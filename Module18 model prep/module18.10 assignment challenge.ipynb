{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge: Factors that affect life expectancy\n",
    "Throughout this module, we dove deep into the topics of exploratory data analysis (EDA) and its substeps. Now it's time to apply your knowledge. In this challenge, you'll work with the Life Expectancy dataset from Kaggle. The data is collected from the websites of the World Health Organisation (WHO) and World Bank (WB). The dataset contains annual variables for many of the countries in the world which are divided into several broad categories: immunization related factors, mortality factors, economical factors, and social factors.\n",
    "\n",
    "https://www.kaggle.com/kumarajarshi/life-expectancy-who\n",
    "\n",
    "You should access the data from the Thinkful database. Here's the credentials you can use to connect to the database:\n",
    "\n",
    "postgres_user = 'dsbc_student'\n",
    "postgres_pw = '7*.8G9QH21'\n",
    "postgres_host = '142.93.121.174'\n",
    "postgres_port = '5432'\n",
    "postgres_db = 'lifeexpectancy'\n",
    "table_name = 'lifeexpectancy'\n",
    "\n",
    "To complete this challenge, submit a Jupyter notebook containing your solutions to the following tasks. Moreover, you can also submit a kernel to the Kaggle containing your solutions.\n",
    "\n",
    "- Your goal in this challenge is to find the factors that affect the life expectancy. Specifically, you need to find out which factors increase the expected life in the countries and which factors decrease it.\n",
    "\n",
    "- First, load the dataset.\n",
    "\n",
    "- Detect the problems with the data such as missing values and outliers. Are there any nonsense values that seem to be stemmed from the data collection? For the missing values, discuss which technique would be the most suitable one in filling out these values. Regarding the outliers, discuss their potential effects on your analysis and select an appropriate method to deal with them.\n",
    "\n",
    "- Explore the data using univariate and multivariate exploration techniques. You should pay special attention to your target variable. In this regard, your focus should be on finding the relevant variables that may affect life expectancy.\n",
    "\n",
    "- In the feature engineering step, you need to select a suite of variables that you think would be ideal in the modeling phase. More concretely, you may discard some variables that are very correlated with the other ones or the variables that you think irrelevant with the life expectancy.\n",
    "\n",
    "- Summarize your findings. One of the most important skills of a data scientist is to convey ideas and findings to nontechnical people using understandable language. In this regard, one of the most effective ways to communicate your ideas is to do it using effective visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import scipy.stats as stats\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 2\n",
    "First, load the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, load the dataset.\n",
    "postgres_user = 'dsbc_student'\n",
    "postgres_pw = '7*.8G9QH21'\n",
    "postgres_host = '142.93.121.174'\n",
    "postgres_port = '5432'\n",
    "postgres_db = 'lifeexpectancy'\n",
    "table_name = 'lifeexpectancy'\n",
    "\n",
    "engine = create_engine('postgresql://{}:{}@{}:{}/{}'.format(\n",
    "    postgres_user, postgres_pw, postgres_host, postgres_port, postgres_db))\n",
    "\n",
    "df_original = pd.read_sql_query('select * from '+ table_name,con=engine)\n",
    "engine.dispose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2938 entries, 0 to 2937\n",
      "Data columns (total 22 columns):\n",
      "Country                            2938 non-null object\n",
      "Year                               2938 non-null int64\n",
      "Status                             2938 non-null object\n",
      "Life expectancy                    2928 non-null float64\n",
      "Adult Mortality                    2928 non-null float64\n",
      "infant deaths                      2938 non-null int64\n",
      "Alcohol                            2744 non-null float64\n",
      "percentage expenditure             2938 non-null float64\n",
      "Hepatitis B                        2385 non-null float64\n",
      "Measles                            2938 non-null int64\n",
      " BMI                               2904 non-null float64\n",
      "under-five deaths                  2938 non-null int64\n",
      "Polio                              2919 non-null float64\n",
      "Total expenditure                  2712 non-null float64\n",
      "Diphtheria                         2919 non-null float64\n",
      " HIV/AIDS                          2938 non-null float64\n",
      "GDP                                2490 non-null float64\n",
      "Population                         2286 non-null float64\n",
      " thinness  1-19 years              2904 non-null float64\n",
      " thinness 5-9 years                2904 non-null float64\n",
      "Income composition of resources    2771 non-null float64\n",
      "Schooling                          2775 non-null float64\n",
      "dtypes: float64(16), int64(4), object(2)\n",
      "memory usage: 505.1+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Year</th>\n",
       "      <th>Status</th>\n",
       "      <th>Life expectancy</th>\n",
       "      <th>Adult Mortality</th>\n",
       "      <th>infant deaths</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>percentage expenditure</th>\n",
       "      <th>Hepatitis B</th>\n",
       "      <th>Measles</th>\n",
       "      <th>...</th>\n",
       "      <th>Polio</th>\n",
       "      <th>Total expenditure</th>\n",
       "      <th>Diphtheria</th>\n",
       "      <th>HIV/AIDS</th>\n",
       "      <th>GDP</th>\n",
       "      <th>Population</th>\n",
       "      <th>thinness  1-19 years</th>\n",
       "      <th>thinness 5-9 years</th>\n",
       "      <th>Income composition of resources</th>\n",
       "      <th>Schooling</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2015</td>\n",
       "      <td>Developing</td>\n",
       "      <td>65.0</td>\n",
       "      <td>263.0</td>\n",
       "      <td>62</td>\n",
       "      <td>0.01</td>\n",
       "      <td>71.279624</td>\n",
       "      <td>65.0</td>\n",
       "      <td>1154</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.16</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>584.259210</td>\n",
       "      <td>33736494.0</td>\n",
       "      <td>17.2</td>\n",
       "      <td>17.3</td>\n",
       "      <td>0.479</td>\n",
       "      <td>10.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2014</td>\n",
       "      <td>Developing</td>\n",
       "      <td>59.9</td>\n",
       "      <td>271.0</td>\n",
       "      <td>64</td>\n",
       "      <td>0.01</td>\n",
       "      <td>73.523582</td>\n",
       "      <td>62.0</td>\n",
       "      <td>492</td>\n",
       "      <td>...</td>\n",
       "      <td>58.0</td>\n",
       "      <td>8.18</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>612.696514</td>\n",
       "      <td>327582.0</td>\n",
       "      <td>17.5</td>\n",
       "      <td>17.5</td>\n",
       "      <td>0.476</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2013</td>\n",
       "      <td>Developing</td>\n",
       "      <td>59.9</td>\n",
       "      <td>268.0</td>\n",
       "      <td>66</td>\n",
       "      <td>0.01</td>\n",
       "      <td>73.219243</td>\n",
       "      <td>64.0</td>\n",
       "      <td>430</td>\n",
       "      <td>...</td>\n",
       "      <td>62.0</td>\n",
       "      <td>8.13</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>631.744976</td>\n",
       "      <td>31731688.0</td>\n",
       "      <td>17.7</td>\n",
       "      <td>17.7</td>\n",
       "      <td>0.470</td>\n",
       "      <td>9.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2012</td>\n",
       "      <td>Developing</td>\n",
       "      <td>59.5</td>\n",
       "      <td>272.0</td>\n",
       "      <td>69</td>\n",
       "      <td>0.01</td>\n",
       "      <td>78.184215</td>\n",
       "      <td>67.0</td>\n",
       "      <td>2787</td>\n",
       "      <td>...</td>\n",
       "      <td>67.0</td>\n",
       "      <td>8.52</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>669.959000</td>\n",
       "      <td>3696958.0</td>\n",
       "      <td>17.9</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.463</td>\n",
       "      <td>9.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2011</td>\n",
       "      <td>Developing</td>\n",
       "      <td>59.2</td>\n",
       "      <td>275.0</td>\n",
       "      <td>71</td>\n",
       "      <td>0.01</td>\n",
       "      <td>7.097109</td>\n",
       "      <td>68.0</td>\n",
       "      <td>3013</td>\n",
       "      <td>...</td>\n",
       "      <td>68.0</td>\n",
       "      <td>7.87</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>63.537231</td>\n",
       "      <td>2978599.0</td>\n",
       "      <td>18.2</td>\n",
       "      <td>18.2</td>\n",
       "      <td>0.454</td>\n",
       "      <td>9.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Country  Year      Status  Life expectancy   Adult Mortality  \\\n",
       "0  Afghanistan  2015  Developing              65.0            263.0   \n",
       "1  Afghanistan  2014  Developing              59.9            271.0   \n",
       "2  Afghanistan  2013  Developing              59.9            268.0   \n",
       "3  Afghanistan  2012  Developing              59.5            272.0   \n",
       "4  Afghanistan  2011  Developing              59.2            275.0   \n",
       "\n",
       "   infant deaths  Alcohol  percentage expenditure  Hepatitis B  Measles   ...  \\\n",
       "0             62     0.01               71.279624         65.0      1154  ...   \n",
       "1             64     0.01               73.523582         62.0       492  ...   \n",
       "2             66     0.01               73.219243         64.0       430  ...   \n",
       "3             69     0.01               78.184215         67.0      2787  ...   \n",
       "4             71     0.01                7.097109         68.0      3013  ...   \n",
       "\n",
       "   Polio  Total expenditure  Diphtheria    HIV/AIDS         GDP  Population  \\\n",
       "0    6.0               8.16         65.0        0.1  584.259210  33736494.0   \n",
       "1   58.0               8.18         62.0        0.1  612.696514    327582.0   \n",
       "2   62.0               8.13         64.0        0.1  631.744976  31731688.0   \n",
       "3   67.0               8.52         67.0        0.1  669.959000   3696958.0   \n",
       "4   68.0               7.87         68.0        0.1   63.537231   2978599.0   \n",
       "\n",
       "    thinness  1-19 years   thinness 5-9 years  \\\n",
       "0                   17.2                 17.3   \n",
       "1                   17.5                 17.5   \n",
       "2                   17.7                 17.7   \n",
       "3                   17.9                 18.0   \n",
       "4                   18.2                 18.2   \n",
       "\n",
       "   Income composition of resources  Schooling  \n",
       "0                            0.479       10.1  \n",
       "1                            0.476       10.0  \n",
       "2                            0.470        9.9  \n",
       "3                            0.463        9.8  \n",
       "4                            0.454        9.5  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_original.info()\n",
    "df_original.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 3\n",
    "Detect the problems with the data such as missing values and outliers. Are there any nonsense values that seem to be stemmed from the data collection? For the missing values, discuss which technique would be the most suitable one in filling out these values. Regarding the outliers, discuss their potential effects on your analysis and select an appropriate method to deal with them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step 3.1 discriptive statistics\n",
    "use df.describe() to examine the data\n",
    "\n",
    "### step 3.2 nonsense value check\n",
    "- for valuables inlcuding 'Adult Mortality', \"infrant deaths', 'Measles', 'under-five deaths', by definition, it is 'Number of Infant Deaths per 1000 population', so it doesn't make sense if certain values are over 1000 for such varialbes. Whilst, we can spot 14 infant deaths records that are over 1000. (i.e. df[df['infant_deaths'] >=1000]), we can change them to nan\n",
    "- also those zero values across 'infant deaths',  'measeles', and such are questionable, but not totally nonsense, so we can just keep them at this point.\n",
    "\n",
    "### step 3.3 fill nan\n",
    "- the data is time seriers, so use interpolate() to fill nan values\n",
    "- also, it makes more sense to fill nan values within each coutry\n",
    "\n",
    "### step 3.4 outliers handeling\n",
    "- to be continued"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Life_expectancy</th>\n",
       "      <th>Adult_Mortality</th>\n",
       "      <th>infant_deaths</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>percentage_expenditure</th>\n",
       "      <th>Hepatitis_B</th>\n",
       "      <th>Measles</th>\n",
       "      <th>BMI</th>\n",
       "      <th>under-five_deaths</th>\n",
       "      <th>Polio</th>\n",
       "      <th>Total_expenditure</th>\n",
       "      <th>Diphtheria</th>\n",
       "      <th>HIV/AIDS</th>\n",
       "      <th>GDP</th>\n",
       "      <th>Population</th>\n",
       "      <th>thinness__1-19_years</th>\n",
       "      <th>thinness_5-9_years</th>\n",
       "      <th>Income_composition_of_resources</th>\n",
       "      <th>Schooling</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>2938.000000</td>\n",
       "      <td>2928.000000</td>\n",
       "      <td>2928.000000</td>\n",
       "      <td>2938.000000</td>\n",
       "      <td>2744.000000</td>\n",
       "      <td>2938.000000</td>\n",
       "      <td>2385.000000</td>\n",
       "      <td>2938.000000</td>\n",
       "      <td>2904.000000</td>\n",
       "      <td>2938.000000</td>\n",
       "      <td>2919.000000</td>\n",
       "      <td>2712.00000</td>\n",
       "      <td>2919.000000</td>\n",
       "      <td>2938.000000</td>\n",
       "      <td>2490.000000</td>\n",
       "      <td>2.286000e+03</td>\n",
       "      <td>2904.000000</td>\n",
       "      <td>2904.000000</td>\n",
       "      <td>2771.000000</td>\n",
       "      <td>2775.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>2007.518720</td>\n",
       "      <td>69.224932</td>\n",
       "      <td>164.796448</td>\n",
       "      <td>30.303948</td>\n",
       "      <td>4.602861</td>\n",
       "      <td>738.251295</td>\n",
       "      <td>80.940461</td>\n",
       "      <td>2419.592240</td>\n",
       "      <td>38.321247</td>\n",
       "      <td>42.035739</td>\n",
       "      <td>82.550188</td>\n",
       "      <td>5.93819</td>\n",
       "      <td>82.324084</td>\n",
       "      <td>1.742103</td>\n",
       "      <td>7483.158469</td>\n",
       "      <td>1.275338e+07</td>\n",
       "      <td>4.839704</td>\n",
       "      <td>4.870317</td>\n",
       "      <td>0.627551</td>\n",
       "      <td>11.992793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>4.613841</td>\n",
       "      <td>9.523867</td>\n",
       "      <td>124.292079</td>\n",
       "      <td>117.926501</td>\n",
       "      <td>4.052413</td>\n",
       "      <td>1987.914858</td>\n",
       "      <td>25.070016</td>\n",
       "      <td>11467.272489</td>\n",
       "      <td>20.044034</td>\n",
       "      <td>160.445548</td>\n",
       "      <td>23.428046</td>\n",
       "      <td>2.49832</td>\n",
       "      <td>23.716912</td>\n",
       "      <td>5.077785</td>\n",
       "      <td>14270.169342</td>\n",
       "      <td>6.101210e+07</td>\n",
       "      <td>4.420195</td>\n",
       "      <td>4.508882</td>\n",
       "      <td>0.210904</td>\n",
       "      <td>3.358920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>36.300000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.37000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.681350</td>\n",
       "      <td>3.400000e+01</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>2004.000000</td>\n",
       "      <td>63.100000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.877500</td>\n",
       "      <td>4.685343</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.300000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>4.26000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>463.935626</td>\n",
       "      <td>1.957932e+05</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.493000</td>\n",
       "      <td>10.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>2008.000000</td>\n",
       "      <td>72.100000</td>\n",
       "      <td>144.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.755000</td>\n",
       "      <td>64.912906</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>43.500000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>5.75500</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1766.947595</td>\n",
       "      <td>1.386542e+06</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>0.677000</td>\n",
       "      <td>12.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>2012.000000</td>\n",
       "      <td>75.700000</td>\n",
       "      <td>228.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>7.702500</td>\n",
       "      <td>441.534144</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>360.250000</td>\n",
       "      <td>56.200000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>7.49250</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>5910.806335</td>\n",
       "      <td>7.420359e+06</td>\n",
       "      <td>7.200000</td>\n",
       "      <td>7.200000</td>\n",
       "      <td>0.779000</td>\n",
       "      <td>14.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>723.000000</td>\n",
       "      <td>1800.000000</td>\n",
       "      <td>17.870000</td>\n",
       "      <td>19479.911610</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>212183.000000</td>\n",
       "      <td>87.300000</td>\n",
       "      <td>2500.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>17.60000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>50.600000</td>\n",
       "      <td>119172.741800</td>\n",
       "      <td>1.293859e+09</td>\n",
       "      <td>27.700000</td>\n",
       "      <td>28.600000</td>\n",
       "      <td>0.948000</td>\n",
       "      <td>20.700000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Year  Life_expectancy  Adult_Mortality  infant_deaths  \\\n",
       "count  2938.000000      2928.000000      2928.000000    2938.000000   \n",
       "mean   2007.518720        69.224932       164.796448      30.303948   \n",
       "std       4.613841         9.523867       124.292079     117.926501   \n",
       "min    2000.000000        36.300000         1.000000       0.000000   \n",
       "25%    2004.000000        63.100000        74.000000       0.000000   \n",
       "50%    2008.000000        72.100000       144.000000       3.000000   \n",
       "75%    2012.000000        75.700000       228.000000      22.000000   \n",
       "max    2015.000000        89.000000       723.000000    1800.000000   \n",
       "\n",
       "           Alcohol  percentage_expenditure  Hepatitis_B        Measles  \\\n",
       "count  2744.000000             2938.000000  2385.000000    2938.000000   \n",
       "mean      4.602861              738.251295    80.940461    2419.592240   \n",
       "std       4.052413             1987.914858    25.070016   11467.272489   \n",
       "min       0.010000                0.000000     1.000000       0.000000   \n",
       "25%       0.877500                4.685343    77.000000       0.000000   \n",
       "50%       3.755000               64.912906    92.000000      17.000000   \n",
       "75%       7.702500              441.534144    97.000000     360.250000   \n",
       "max      17.870000            19479.911610    99.000000  212183.000000   \n",
       "\n",
       "               BMI  under-five_deaths        Polio  Total_expenditure  \\\n",
       "count  2904.000000        2938.000000  2919.000000         2712.00000   \n",
       "mean     38.321247          42.035739    82.550188            5.93819   \n",
       "std      20.044034         160.445548    23.428046            2.49832   \n",
       "min       1.000000           0.000000     3.000000            0.37000   \n",
       "25%      19.300000           0.000000    78.000000            4.26000   \n",
       "50%      43.500000           4.000000    93.000000            5.75500   \n",
       "75%      56.200000          28.000000    97.000000            7.49250   \n",
       "max      87.300000        2500.000000    99.000000           17.60000   \n",
       "\n",
       "        Diphtheria     HIV/AIDS            GDP    Population  \\\n",
       "count  2919.000000  2938.000000    2490.000000  2.286000e+03   \n",
       "mean     82.324084     1.742103    7483.158469  1.275338e+07   \n",
       "std      23.716912     5.077785   14270.169342  6.101210e+07   \n",
       "min       2.000000     0.100000       1.681350  3.400000e+01   \n",
       "25%      78.000000     0.100000     463.935626  1.957932e+05   \n",
       "50%      93.000000     0.100000    1766.947595  1.386542e+06   \n",
       "75%      97.000000     0.800000    5910.806335  7.420359e+06   \n",
       "max      99.000000    50.600000  119172.741800  1.293859e+09   \n",
       "\n",
       "       thinness__1-19_years  thinness_5-9_years  \\\n",
       "count           2904.000000         2904.000000   \n",
       "mean               4.839704            4.870317   \n",
       "std                4.420195            4.508882   \n",
       "min                0.100000            0.100000   \n",
       "25%                1.600000            1.500000   \n",
       "50%                3.300000            3.300000   \n",
       "75%                7.200000            7.200000   \n",
       "max               27.700000           28.600000   \n",
       "\n",
       "       Income_composition_of_resources    Schooling  \n",
       "count                      2771.000000  2775.000000  \n",
       "mean                          0.627551    11.992793  \n",
       "std                           0.210904     3.358920  \n",
       "min                           0.000000     0.000000  \n",
       "25%                           0.493000    10.100000  \n",
       "50%                           0.677000    12.300000  \n",
       "75%                           0.779000    14.300000  \n",
       "max                           0.948000    20.700000  "
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make a copy of the orignial dataframe, df\n",
    "df = df_original.copy()\n",
    "\n",
    "# get rid of the white space at the end of column names, and change with '_' in between\n",
    "df.columns = df.columns.str.rstrip()\n",
    "df.columns = df.columns.str.lstrip()\n",
    "df.columns = df.columns.str.replace(' ', '_')\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get rid of nonsense values and replace with np.nan, \n",
    "for col in ['Adult_Mortality', 'infant_deaths', 'Measles', 'under-five_deaths']:\n",
    "# for col in ['under-five deaths']:    \n",
    "#     print(df.loc[df[col] >=1000, col])\n",
    "    df.loc[df[col] >=1000, col] = np.nan\n",
    "\n",
    "# fill nan within coutries\n",
    "for col in df.columns.unique():\n",
    "    if col not in ['Country', 'Year', 'Status']:\n",
    "        for country in df.Country.unique():\n",
    "            df.loc[df.Country==country, col] = df.loc[df.Country==country, col].interpolate()\n",
    "# then drop nan\n",
    "df = df.dropna()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### potiential effects of outliers\n",
    "- They skew the descriptive statistics of the data. For example, consider one of the most commonly used descriptive statistics—the mean. This value can be severely skewed by outliers.\n",
    "- Some machine learning models are sensitive to extreme values. In order to get more accurate estimates, we need to eliminate those values from our dataset.\n",
    "\n",
    "### step 3.4 outliers handeling\n",
    "- use boxplot to visualize outliers, set whis=1.5\n",
    "- use winsorization to drop outliers. \n",
    "\n",
    "##### Note: \n",
    "- I performed two trials for winsorization. The 1st trial uses fixed threshold, the 2nd trial uses flexible threshold based on how many outliers are there for each column. \n",
    "- both trials can get rid of all the outliers, but\n",
    "- the result of 2nd trial is perferable, since more data can remain its orignial values.\n",
    "- it is also possible to transform the outliers, i.e. using log transformation. I didn't perform in this stage though, but as a reminder, I will perform log transformation later if desired. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# work on outliers\n",
    "\n",
    "# life_expectancy: our target\n",
    "plt.boxplot(df['Life_expectancy'])\n",
    "plt.title(\"{} (whis=1.5)\".format('Life_expectancy'))\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(15, 20))\n",
    "for col,index in zip(df.columns.unique(), range(len(df.columns.unique()))):\n",
    "    if col not in ['Country', 'Year', 'Status', 'Life_expectancy']:\n",
    "        plt.subplot(6,3,index-3)\n",
    "        plt.boxplot(df[col])\n",
    "        plt.title(\"{} (whis=1.5)\".format(col))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# working on outliers \n",
    "# count outliers under 1.5 threshold, represent in portion for later use in winsorization\n",
    "threshold = 1.5\n",
    "record_num = len(df)\n",
    "\n",
    "lower_list = []\n",
    "upper_list = []\n",
    "for col,index in zip(df.columns.unique(), range(len(df.columns.unique()))):\n",
    "    if col not in ['Country', 'Year', 'Status']:\n",
    "        q75, q25 = np.percentile(df[col], [75 ,25])\n",
    "        iqr = q75 - q25\n",
    "        min_val = q25 - (iqr*threshold)\n",
    "        max_val = q75 + (iqr*threshold)\n",
    "#         store the upper bound and lower bound\n",
    "        lower_list.append(len(np.where((df[col] < min_val))[0]) / record_num)\n",
    "        upper_list.append(len(np.where((df[col] > max_val))[0]) / record_num)\n",
    "        print(\"{:25s} : \".format(col)\n",
    "        + \"percentile of lower outliers is: {:2f},\\t   \".format(len(np.where((df[col] < min_val))[0]) / record_num)\\\n",
    "        + \"percentile of upper outliers is: {:2f}. \".format(len(np.where((df[col] > max_val))[0]) / record_num)  \\                                          \n",
    "                                                )\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trial 1, perform winsorization, use fixed threshold (0.12, 0.16) for all columns\n",
    "\n",
    "import scipy.stats.mstats\n",
    "\n",
    "df_winsor = df.copy()\n",
    "winsorized_list = []\n",
    "for col,index in zip(df_winsor.columns.unique(), range(len(df_winsor.columns.unique()))):\n",
    "    if col not in ['Country', 'Year', 'Status']:\n",
    "        df_winsor['winsorized_'+ col] = scipy.stats.mstats.winsorize(df_winsor[col], (0.12, 0.16))\n",
    "        winsorized_list.append('winsorized_'+ col)\n",
    "\n",
    "        \n",
    "plt.boxplot(df_winsor['winsorized_'+'Life_expectancy'])\n",
    "plt.title(\"{} (whis=1.5)\".format('winsorized_'+'Life_expectancy'))\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(15, 20))\n",
    "for col,index in zip(winsorized_list, range(len(winsorized_list))):\n",
    "    if col not in ['Country', 'Year', 'Status', 'winsorized_'+'Life_expectancy']:\n",
    "        plt.subplot(6,3,index)\n",
    "        plt.boxplot(df_winsor[col])\n",
    "        plt.title(\"{} (whis=1.5)\".format(col))\n",
    "plt.show()\n",
    "\n",
    "df_trial1 = df_winsor.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trial 2, perform winsorization, use flexible threshold for each column, based on the percentile of outiers\n",
    "\n",
    "# import scipy.stats.mstats\n",
    "\n",
    "df_winsor = df.copy()\n",
    "winsorized_list = []\n",
    "for col in df.columns.unique():\n",
    "    if col not in ['Country', 'Year', 'Status']:\n",
    "        winsorized_list.append( col)\n",
    "    \n",
    "    \n",
    "for col,index in zip(winsorized_list, range(len(winsorized_list))):\n",
    "#     if col not in ['Country', 'Year', 'Status']:\n",
    "    df_winsor['winsorized_'+ col] = scipy.stats.mstats.winsorize(df_winsor[col], (lower_list[index], upper_list[index]))\n",
    "#         winsorized_list.append('winsorized_'+ col)\n",
    "\n",
    "        \n",
    "plt.boxplot(df_winsor['winsorized_'+'Life_expectancy'])\n",
    "plt.title(\"{} (whis=1.5)\".format('winsorized_'+'Life_expectancy'))\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(15, 20))\n",
    "for col,index in zip(winsorized_list[1:], range(len(winsorized_list[1:]))):\n",
    "    plt.subplot(6,3,index+1)\n",
    "    plt.boxplot(df_winsor['winsorized_'+ col])\n",
    "    plt.title(\"{} (whis=1.5)\".format('winsorized_'+col))\n",
    "plt.show()\n",
    "\n",
    "df_trial2 = df_winsor.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 4\n",
    "Explore the data using univariate and multivariate exploration techniques. You should pay special attention to your target variable. In this regard, your focus should be on finding the relevant variables that may affect life expectancy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### univariant exploration\n",
    "- we can choose discriptive statistics method (i.e. .describe())\n",
    "- or visulization method, (i.e. histogram or boxplot) for continous variables, which is the case in this challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# univariant exploration\n",
    "# visulization of distribution using histogram\n",
    "\n",
    "plt.hist(df_winsor['winsorized_'+'Life_expectancy'])\n",
    "plt.title(\"{} \".format('winsorized_'+'Life_expectancy'))\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(15, 20))\n",
    "for col,index in zip(winsorized_list[1:], range(len(winsorized_list[1:]))):\n",
    "    plt.subplot(6,3,index+1)\n",
    "    plt.hist(df_winsor['winsorized_'+ col])\n",
    "    plt.title(\"{} \".format('winsorized_'+col))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step 4. 1 multivariant exploration\n",
    "we are focusing on finding the correlation, and the mothods include\n",
    "- scatter plot\n",
    "- correlation matrix, i.e. .corr()\n",
    "- heatmap\n",
    "\n",
    "in this challenge, I will choose scatter plot and heatmap method, because the information in correlation matrix can be covered from heatmap has well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter plot to show correlation between each column and the target variable\n",
    "# at the first glance, adult_motality, HIV/AIDS, composition_of_resource, and schooling \n",
    "# have high coorelation with our target variable life_expectancy\n",
    "\n",
    "# work on the winsorized part\n",
    "df_clean = df_winsor.iloc[:,22:].copy()\n",
    "\n",
    "plt.figure(figsize=(15, 20))\n",
    "for col,index in zip(df_clean.columns.unique()[1:], range(len(df_clean.columns.unique()[1:]))):\n",
    "    plt.subplot(6,3,index+1)\n",
    "    plt.scatter(df_winsor[col], df_winsor['winsorized_'+'Life_expectancy'])\n",
    "    plt.title(\"{} - Life_expectancy (target)\".format(col))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# calculate the correlation coefficient and illustrate using heatmap\n",
    "plt.figure(figsize=(15,15))\n",
    "\n",
    "# draw the heatmap using seaborn.\n",
    "sns.heatmap(df_clean.corr(), square=True, annot=True, linewidths=.5)\n",
    "# plt.title(\"correlation matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### intermediate summary for step 4\n",
    "- the relationship between the target variable and the rest can be represented by correlationship/ colinearity\n",
    "- we can use visulazation (scatter plot) or use discriptive statistics (correlation coefficient) to illustrate correlationship\n",
    "- In this study case, the top correlation between target variable and the rest of the column is income_composition_of_resource = 0.82, HIV/AIDS = -0.79, schooling = 0.76, \n",
    "- normally, a correlation coeffient higher than 0.7 indicates strong correlationship, (either positive or negative). So, the relevant variables tha may affect life expectancy including \"income_composition_of_resource\" (cc=0.82), \"HIV/AIDS\" (cc=-0.79), \"schooling\" (cc=0.76)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 5\n",
    "In the feature engineering step, you need to select a suite of variables that you think would be ideal in the modeling phase. More concretely, you may discard some variables that are very correlated with the other ones or the variables that you think irrelevant with the life expectancy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANS:\n",
    "we can apply a mask on the heat map to highlight very low and/or very high correlation coefficient\n",
    "- High cc check. High correlation coefficient pair include infant_deaths- under-five_deaths (cc=0.99), thinness__1-19_years - thinness_5-9_years (cc=0.93), percentage_expenditure-GDP (cc=0.92), Income_composition_of_resources – schooling(cc=0.88), Polio-Diphtheria (cc=0.84), \n",
    "- Since,high correlation coefficient might cause unstability, we can get rid of one variable in each of the pair. I chose to drop the one with weaker CC with our target variables, i.e. drop infant_deaths, thinness_5-9_years, GDP, schooling, polio.\n",
    "- Low cc check. This time, we drop columns have very low correlation with the target variable. The one we would drop is Population (cc=-0.023)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# calculate the correlation coefficient and illustrate using heatmap\n",
    "plt.figure(figsize=(15,15))\n",
    "df_corr_matrix = df_clean.corr()\n",
    "# apply a mask on the corr, that only show high correlation (cc>=0.7), and under triangle part\n",
    "df_corr_matrix.iloc[1:,1:][np.abs(df_corr_matrix)<.7] = -10\n",
    "# draw the heatmap using seaborn.\n",
    "sns.heatmap(df_corr_matrix, square=True, annot=True, linewidths=.5)\n",
    "# plt.title(\"correlation matrix\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "df_corr_matrix = df_clean.corr()\n",
    "# apply a mask on the corr, that only show low correlation (cc<0.1), and under triangle part\n",
    "df_corr_matrix[np.abs(df_corr_matrix)>.1] = 10\n",
    "# draw the heatmap using seaborn.\n",
    "sns.heatmap(df_corr_matrix, square=True, annot=True, linewidths=.5)\n",
    "# plt.title(\"correlation matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# drop the columns and make a copy of new dataframe to work on.\n",
    "\n",
    "col_list_new = ['winsorized_Life_expectancy', 'winsorized_Adult_Mortality',\n",
    "       'winsorized_Alcohol', 'winsorized_percentage_expenditure',\n",
    "       'winsorized_Hepatitis_B', 'winsorized_Measles', 'winsorized_BMI',\n",
    "       'winsorized_under-five_deaths',\n",
    "       'winsorized_Total_expenditure', 'winsorized_Diphtheria',\n",
    "       'winsorized_HIV/AIDS', \n",
    "       'winsorized_thinness__1-19_years',\n",
    "       'winsorized_Income_composition_of_resources']\n",
    "\n",
    "df_trimmed = df_clean[col_list_new].copy()\n",
    "df_trimmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_trimmed.columns.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 6\n",
    "Summarize your findings. One of the most important skills of a data scientist is to convey ideas and findings to nontechnical people using understandable language. In this regard, one of the most effective ways to communicate your ideas is to do it using effective visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  step 6. 1 data cleaning. \n",
    "- we have filled missing values using interpolation within contries, then dropna\n",
    "- then we got rid of outliers under whis=1.5, using winsorization\n",
    "- let's review the data using discriptive statistics methods, and visulization (boxplot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trimmed.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data visulization\n",
    "        \n",
    "plt.boxplot(df_trimmed['winsorized_'+'Life_expectancy'])\n",
    "plt.title(\"{} (whis=1.5)\".format('Life_expectancy'))\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(15, 20))\n",
    "for col,index in zip(df_trimmed.columns.unique()[1:], range(len(df_trimmed.columns.unique()[1:]))):\n",
    "    plt.subplot(6,3,index+1)\n",
    "    plt.boxplot(df_trimmed[col])\n",
    "    plt.title(\"{} (whis=1.5)\".format(col))\n",
    "plt.show()\n",
    "\n",
    "df_trial2 = df_winsor.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step 6. 2 data exploration\n",
    "- for univariant analysis, we can plot the distribution using histogram\n",
    "- note that for some cases normaility is required, so we can perform boxcox tranformation to make the distribution more normal\n",
    "\n",
    "- for multivariant analysis, we care about the correlationship between each variable and our target varialbe, also coorelationship between each non-target variable.\n",
    "- we can use scatter plot to visulize the correlationship\n",
    "- we can calculate correlation coefficient (CC) to quantify correlationship and use heat map to display that, which is helpful when illustrating correlationship between each pair of the non-target variables.\n",
    "- we can spot some variables have high-correlation with the target variables, i.e. \"income_composition_of_resource\" (cc=0.82), \"HIV/AIDS\" (cc=-0.79), \"schooling\" (cc=0.76). (please see analysis in step 5)\n",
    "- For cases including PCA, we might want to get rid of certain variables that are high-coorelated with each other within the non-target variable pairs, as well as variables that have very low correlation with the target variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# univariant exploration\n",
    "# visulization of distribution using histogram\n",
    "\n",
    "plt.hist(df_trimmed['winsorized_'+'Life_expectancy'])\n",
    "plt.title(\"{} \".format('Life_expectancy'))\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(15, 20))\n",
    "for col,index in zip(df_trimmed.columns.unique()[1:], range(len(df_trimmed.columns.unique()[1:]))):\n",
    "    plt.subplot(6,3,index+1)\n",
    "    plt.hist(df_trimmed[col])\n",
    "    plt.title(\"{} \".format(col))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform normality check\n",
    "from scipy.stats import jarque_bera\n",
    "from scipy.stats import normaltest\n",
    "\n",
    "for col,index in zip(df_trimmed.columns.unique(), range(len(df_trimmed.columns.unique()))):\n",
    "    jb_stats = jarque_bera(df_trimmed[col])\n",
    "    norm_stats = normaltest(df_trimmed[col])\n",
    "    print(col)\n",
    "    print(\"Jarque-Bera test statistics is {0} and p value is {1}\".format(jb_stats[0], jb_stats[1]))\n",
    "    print(\"Normality test statistics is {0} and p value is {1}\".format(norm_stats[0], norm_stats[1]))\n",
    "    print('-------------')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import boxcox\n",
    "    \n",
    "# perform boxcox\n",
    "# make a copy\n",
    "df_boxcox = df_trimmed.copy()\n",
    "\n",
    "# boxcox require all datapoints larger than zero, perform the following:\n",
    "df_boxcox.iloc[np.abs(df_boxcox)<.001] = np.nan\n",
    "df_boxcox = df_boxcox.dropna()\n",
    "\n",
    "for col,index in zip(df_boxcox.columns.unique(), range(len(df_boxcox.columns.unique()))):\n",
    "    df_boxcox[col], _ = boxcox(df_boxcox[col])\n",
    "\n",
    "# display the distribution\n",
    "\n",
    "plt.hist(df_boxcox['winsorized_'+'Life_expectancy'])\n",
    "plt.title(\"{} \".format('Life_expectancy'))\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(15, 20))\n",
    "for col,index in zip(df_boxcox.columns.unique()[1:], range(len(df_boxcox.columns.unique()[1:]))):\n",
    "    plt.subplot(6,3,index+1)\n",
    "    plt.hist(df_boxcox[col])\n",
    "    plt.title(\"{} \".format(col))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# explore multivariant variable for variables after coxbox, check correlation coefficient once again\n",
    "\n",
    "# calculate the correlation coefficient and illustrate using heatmap\n",
    "plt.figure(figsize=(15,15))\n",
    "df_corr_matrix = df_boxcox.corr()\n",
    "# apply a mask on the corr, that only show high correlation (cc>=0.7), and under triangle part\n",
    "df_corr_matrix.iloc[1:,1:][np.abs(df_corr_matrix)<.7] = -10\n",
    "# draw the heatmap using seaborn.\n",
    "sns.heatmap(df_corr_matrix, square=True, annot=True, linewidths=.5)\n",
    "# plt.title(\"correlation matrix\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "df_corr_matrix = df_boxcox.corr()\n",
    "# apply a mask on the corr, that only show low correlation (cc<0.1), and under triangle part\n",
    "df_corr_matrix[np.abs(df_corr_matrix)>.1] = 10\n",
    "# draw the heatmap using seaborn.\n",
    "sns.heatmap(df_corr_matrix, square=True, annot=True, linewidths=.5)\n",
    "# plt.title(\"correlation matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step 6. 3 feature engineering - PCA\n",
    "- the former steps ensure that the prerequisites for performing PCA satisfiy\n",
    "- we have tweleve variables before performing PCA, and we can choose the first 8 principle compoenets. \n",
    "- The choice is made based on the eigen values and their explained variance ratio. Note that, such first 8 principle components, in total, can explain 90% of the varaiance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA# perform PCA, (the prerequisites for PCA satisfied)\n",
    "\n",
    "# Normalize the data so that all variables have a mean of 0 and standard deviation\n",
    "# of 1.\n",
    "X = StandardScaler().fit_transform(df_boxcox.iloc[:,1:])\n",
    "# np.shape(X)\n",
    "\n",
    "sklearn_pca = PCA(n_components=12)\n",
    "Y_sklearn = sklearn_pca.fit_transform(X)\n",
    "\n",
    "print(\n",
    "    'The percentage of total variance in the dataset explained by each',\n",
    "    'component from Sklearn PCA.\\n',\n",
    "    sklearn_pca.explained_variance_ratio_\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating eigenvalues and eigenvectors.\n",
    "Cx = np.cov(X.T)\n",
    "eig_val_cov, eig_vec_cov = np.linalg.eig(Cx)\n",
    "# sort\n",
    "idx = eig_val_cov.argsort()[::-1]   \n",
    "eig_val_cov = eig_val_cov[idx]\n",
    "eig_vec_cov = eig_vec_cov[:,idx]\n",
    "\n",
    "# Inspecting the eigenvalues and eigenvectors.\n",
    "# for i in range(len(eig_val_cov)):\n",
    "#     eigvec_cov = eig_vec_cov[:, i].T\n",
    "#     print('Eigenvector {}: \\n{}'.format(i + 1, eigvec_cov))\n",
    "#     print('Eigenvalue {}: {}'.format(i + 1, eig_val_cov[i]))\n",
    "#     print(40 * '-')\n",
    "\n",
    "print(\n",
    "    'The percentage of total variance in the dataset explained by each',\n",
    "    'component calculated by hand.\\n',\n",
    "    eig_val_cov / sum(eig_val_cov)\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(eig_val_cov)\n",
    "plt.subplot(2,1,2)\n",
    "eigen_sum = 0\n",
    "elgen_sum_list =[]\n",
    "for eigen_val in sklearn_pca.explained_variance_ratio_:\n",
    "    eigen_sum += eigen_val\n",
    "    elgen_sum_list.append(eigen_sum)\n",
    "    plt.plot(elgen_sum_list)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step 6. 4 one more point\n",
    "the boxcox transformation was performed after we drop the outliers, but note that boxcox transformation will affect distritrion, thus the outliers. If we have performed the boxcox transformation before not after outlier handeling, then result would be different."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
